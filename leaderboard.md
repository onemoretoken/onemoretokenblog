---
layout: page
title: Leaderboard
permalink: /leaderboard/
---

| Model                                      | Runs | Precision | Recall | F1 Score | Accuracy | Avg TP | Avg FP | Avg FN | Price/M   | Comment                                           |
|--------------------------------------------|------|-----------|--------|----------|----------|--------|--------|--------|-----------|---------------------------------------------------|
| openai/gpt-5.1                             | 3    | 0.355     | 0.175  | 0.234    | 0.949    | 3.67   | 6.67   | 17.33  | $7.0833   | Good                                              |
| openai/gpt-5-pro                           | 3    | 0.345     | 0.175  | 0.232    | 0.948    | 3.67   | 7.00   | 17.33  | $85.0000  | Very good, detailed, but so incredibly expensive  |
| z-ai/glm-4.6                               | 3    | 0.368     | 0.175  | 0.225    | 0.953    | 3.67   | 4.67   | 17.33  | $1.3000   | OK-ish, unpredictable at times                                              |
| moonshotai/kimi-k2-0905                    | 3    | 0.500     | 0.143  | 0.222    | 0.956    | 3.00   | 3.00   | 18.00  | $1.3967   | Meh                                                  |
| google/gemini-3-pro-preview                | 3    | 0.429     | 0.143  | 0.214    | 0.953    | 3.00   | 4.00   | 18.00  | $8.6667   | Nothing impressive in spite of the insane hype                                                  |
| moonshotai/kimi-k2                         | 3    | 0.248     | 0.190  | 0.213    | 0.936    | 4.00   | 13.00  | 17.00  | $1.7667   |                                                   |
| deepseek/deepseek-v3.2-exp                 | 3    | 0.403     | 0.143  | 0.210    | 0.953    | 3.00   | 4.33   | 18.00  | $0.3567   | For the very good price, this is a pretty decent model     |
| x-ai/grok-4                                | 3    | 0.313     | 0.159  | 0.209    | 0.946    | 3.33   | 7.67   | 17.67  | $11.0000  | It's alright, nothing worth 11$/M tokens                                                 |
| google/gemini-2.5-pro                      | 3    | 0.347     | 0.143  | 0.202    | 0.950    | 3.00   | 5.67   | 18.00  | $7.0833   |                                                   |
| z-ai/glm-4.5-air                           | 3    | 0.189     | 0.206  | 0.170    | 0.907    | 4.33   | 27.33  | 16.67  | $0.6100   | It's cheap and OK-ish, but it's output is finicky and requires fondling and babysitting                                                  |
| nvidia/llama-3.3-nemotron-super-49b-v1.5   | 3    | 0.450     | 0.095  | 0.157    | 0.956    | 2.00   | 2.00   | 19.00  | $0.3000   | OK, haven't used it enough to comment much more.                                                  |
| anthropic/claude-sonnet-4.5                | 3    | 0.296     | 0.095  | 0.143    | 0.949    | 2.00   | 5.00   | 19.00  | $11.0000  | OK, overgrown ear, putting lipstick on a pig                                                  |
| google/gemini-2.5-flash                    | 3    | 0.286     | 0.095  | 0.143    | 0.949    | 2.00   | 5.00   | 19.00  | $1.7667   | Fast, cheap, OK, too unpredictable, very eager                                                  |
| minimax/minimax-m2                         | 3    | 0.242     | 0.190  | 0.134    | 0.897    | 4.00   | 31.67  | 17.00  | $0.7650   | Trained on OpenAI and Claude responses, nothing special                                                 |
| moonshotai/kimi-k2-thinking                | 3    | 0.174     | 0.127  | 0.133    | 0.919    | 2.67   | 20.00  | 18.33  | $1.7167   |                                                   |
| deepseek/deepseek-v3.1-terminus            | 3    | 0.257     | 0.079  | 0.121    | 0.949    | 1.67   | 4.67   | 19.33  | $0.6767   |                                                   |
| deepseek/deepseek-chat-v3-0324             | 3    | 0.289     | 0.079  | 0.120    | 0.951    | 1.67   | 4.00   | 19.33  | $0.6400   |                                                   |
| openai/chatgpt-4o-latest                   | 3    | 0.278     | 0.063  | 0.103    | 0.951    | 1.33   | 3.33   | 19.67  | $11.6667  |                                                   |
| deepseek/deepseek-r1-0528                  | 3    | 0.267     | 0.063  | 0.103    | 0.951    | 1.33   | 3.67   | 19.67  | $3.0667   |                                                   |
| qwen/qwen3-max                             | 3    | 0.134     | 0.111  | 0.081    | 0.896    | 2.33   | 30.33  | 18.67  | $4.4000   |                                                   |
| x-ai/grok-4.1-fast                         | 3    | 0.250     | 0.048  | 0.079    | 0.951    | 1.00   | 3.33   | 20.00  | $11.0000  |                                                   |
| anthropic/claude-haiku-4.5                 | 3    | 0.200     | 0.048  | 0.077    | 0.949    | 1.00   | 4.00   | 20.00  | $3.6667   |                                                   |
| openai/gpt-5-mini                          | 3    | 0.178     | 0.048  | 0.075    | 0.951    | 1.00   | 3.00   | 20.00  | $1.4167   |                                                   |
| openai/gpt-oss-120b                        | 3    | 0.085     | 0.048  | 0.058    | 0.942    | 1.00   | 7.33   | 20.00  | $0.2800   |                                                   |
| openai/gpt-5-nano                          | 3    | 0.167     | 0.016  | 0.029    | 0.955    | 0.33   | 0.67   | 20.67  | $0.2833   |                                                   |
| openai/gpt-5.1-chat                        | 3    | 0.111     | 0.016  | 0.028    | 0.953    | 0.33   | 1.67   | 20.67  | $7.0833   |                                                   |
| nousresearch/hermes-3-llama-3.1-405b       | 3    | 0.083     | 0.016  | 0.027    | 0.949    | 0.33   | 3.33   | 20.67  | $1.0000   |                                                   |
| anthropic/claude-opus-4.1                  | 3    | 0.000     | 0.000  | 0.000    | 0.945    | 0.00   | 5.00   | 21.00  | $55.0000  |                                                   |
| qwen/qwen3-coder                           | 3    | 0.000     | 0.000  | 0.000    | 0.947    | 0.00   | 4.00   | 21.00  | $0.7067   |                                                   |
| ai21/jamba-large-1.7                       | 3    | 0.000     | 0.000  | 0.000    | 0.953    | 0.00   | 1.33   | 21.00  | $6.0000   |                                                   |
| nvidia/llama-3.1-nemotron-ultra-253b-v1    | 3    | 0.000     | 0.000  | 0.000    | 0.946    | 0.00   | 4.67   | 21.00  | $1.4000   |                                                   |
