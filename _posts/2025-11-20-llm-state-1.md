---
layout: post
title: "Overfitting is ruining LLM-leaderboards"
---

The degree of overfitting *(Overfitting means the system learned not the pattern you want it to learn, but rather just knows it's training data completely)* in LLM-leaderboards these days is so bad that you can barely trust a single chart at this point.
This is perfectly exemplified by the current state of https://artificialanalysis.ai/leaderboards/models and https://huggingface.co/spaces/ArtificialAnalysis/LLM-Performance-Leaderboard IMHO.
Gemini 3 Pro as 1st, Kimi-K2 Thinking as 2nd-3rd and gpt-oss-120B (high) a a score of 61. :nausea

Due to this **extreme** *personal* disconnect surrounding these charts I've concocted a little test that IMO tests the LLMs in a way that that does not conflict with my own personal miscellanous usage of them.
Without further ado, here are the results:

## Tokenfiend's LLM Leaderboard - 3 runs (averaged)
- Temperature set to 0 for consistency.
- (https://www.geeksforgeeks.org/machine-learning/f1-score-in-machine-learning/)

| Model                                     | TP | FP | FN | Precision | Recall | F1 Score | Accuracy | Comment |
|-------------------------------------------|----|----|----|-----------| -------|----------|----------|---------|
| qwen/qwen3-max                            | 4  | 3  | 17 | 0.571     | 0.190  | 0.286    | 0.958    |         |
| z-ai/glm-4.5-air                          | 4  | 3  | 17 | 0.571     | 0.190  | 0.286    | 0.958    |         |
| openai/gpt-5.1                            | 4  | 5  | 17 | 0.444     | 0.190  | 0.267    | 0.953    |         |
| openai/gpt-5-pro                          | 4  | 5  | 17 | 0.444     | 0.190  | 0.267    | 0.953    |         |
| openai/gpt-5.1                            | 4  | 6  | 17 | 0.400     | 0.190  | 0.258    | 0.951    |         |
| openai/gpt-5.1                            | 4  | 6  | 17 | 0.400     | 0.190  | 0.258    | 0.951    |         |
| moonshotai/kimi-k2-0905                   | 3  | 2  | 18 | 0.600     | 0.143  | 0.231    | 0.958    |         |
| google/gemini-2.5-flash                   | 3  | 3  | 18 | 0.500     | 0.143  | 0.222    | 0.956    |         |
| google/gemini-3-pro-preview               | 3  | 3  | 18 | 0.500     | 0.143  | 0.222    | 0.956    |         |
| anthropic/claude-sonnet-4.5               | 3  | 4  | 18 | 0.429     | 0.143  | 0.214    | 0.953    |         |
| x-ai/grok-4                               | 3  | 5  | 18 | 0.375     | 0.143  | 0.207    | 0.951    |         |
| x-ai/grok-4.1-fast                        | 3  | 6  | 18 | 0.333     | 0.143  | 0.200    | 0.949    |         |
| google/gemini-2.5-pro                     | 3  | 8  | 18 | 0.273     | 0.143  | 0.188    | 0.945    |         |
| minimax/minimax-m2                        | 6  | 42 | 15 | 0.125     | 0.286  | 0.174    | 0.879    |         |
| qwen/qwen3-coder                          | 2  | 4  | 19 | 0.333     | 0.095  | 0.148    | 0.951    |         |
| openai/gpt-oss-120b                       | 2  | 7  | 19 | 0.222     | 0.095  | 0.133    | 0.945    |         |
| nvidia/llama-3.1-nemotron-ultra-253b-v1   | 1  | 2  | 20 | 0.333     | 0.048  | 0.083    | 0.953    |         |
| ai21/jamba-large-1.7                      | 1  | 2  | 20 | 0.333     | 0.048  | 0.083    | 0.953    |         |
| anthropic/claude-haiku-4.1                | 1  | 3  | 20 | 0.250     | 0.048  | 0.080    | 0.951    |         |
| deepseek/deepseek-chat-v3-0324            | 1  | 4  | 20 | 0.200     | 0.048  | 0.077    | 0.949    |         |
| anthropic/claude-opus-4.1                 | 1  | 5  | 20 | 0.167     | 0.048  | 0.074    | 0.947    |         |
| deepseek/deepseek-v3.2-exp                | 1  | 5  | 20 | 0.167     | 0.048  | 0.074    | 0.947    |         |
| deepseek/deepseek-v3.1-terminus           | 1  | 5  | 20 | 0.167     | 0.048  | 0.074    | 0.947    |         |
| deepseek/deepseek-r1-0528                 | 1  | 6  | 20 | 0.143     | 0.048  | 0.071    | 0.945    |         |
| moonshotai/kimi-k2-thinking               | 1  | 9  | 20 | 0.100     | 0.048  | 0.065    | 0.939    |         |
| nvidia/llama-3.3-nemotron-super-49b-v1.5  | 0  | 1  | 21 | 0.000     | 0.000  | 0.000    | 0.953    |         |
| nousresearch/hermes-3-llama-3.1-405b      | 0  | 3  | 21 | 0.000     | 0.000  | 0.000    | 0.949    |         |
| openai/gpt-5.1-chat                       | 0  | 0  | 21 | 0.000     | 0.000  | 0.000    | 0.956    |         |
| moonshotai/kimi-k2                        | 0  | 1  | 21 | 0.000     | 0.000  | 0.000    | 0.953    |         |
| z-ai/glm-4.6                              | 0  | 7  | 21 | 0.000     | 0.000  | 0.000    | 0.941    |         |
| openai/gpt-5-mini                         | 0  | 2  | 21 | 0.000     | 0.000  | 0.000    | 0.951    |         |
| openai/gpt-5-nano                         | 0  | 1  | 21 | 0.000     | 0.000  | 0.000    | 0.953    |         |
| openai/chatgpt-4o-latest                  | 0  | 3  | 21 | 0.000     | 0.000  | 0.000    | 0.949    |         |


*Last updated: {{ "now" | date: "%B %Y" }}*